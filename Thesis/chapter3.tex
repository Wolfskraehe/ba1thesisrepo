\chapter{Artificial Immune System}
\label{chap:ais}
\section{Basics of an AIS}
A definition of an AIS is given by \cite[p. 5]{tan2016artificial}:
"Artificial Immune System (AIS) is a computational intelligence system inspired by the working mechanism and principles of the biological immune system."\\An AIS can be used in machine learning and is comparable to an artificial neural net in terms of different application fields.
It shares some similarities with genetic algorithms due to the cloning and mutation process in clonal selection.\\\\
Generally speaking: a set of detectors (Ab) react to a specific anomaly (Ag). In computational science there is usually no distinction between a T cell and a B cell, most artificial immune system generalize both into an Ab. The Ag could be malicious code, an IP address and port combination not allowed in the network or a pattern to be classified. What represents an Ag in the algorithm depends on the context and the use of the algorithm. An AIS can be used in an Intrusion Detection System \cite{PAM17}, learning and pattern recognition \cite{DEC02}, for recommender systems, data mining and clustering \cite{burke2013} and optimization \cite{NAN08}. Control engineering, fault diagnosis and robotics are also application fields of an AIS \cite{tan2016artificial}\\

The basic steps of an AIS can be summarized as shown in \cite{tan2016artificial}:
\begin{enumerate}
	\item 	Initialize/present antigen
	\item 	Initialize antibody population
	\item 	Calculate affinity to the antigen for each antibody
	\item 	Check life cycle of each antibody and update it
	\item 	If stopping condition met go to 6 else go to 3
	\item 	Output antibody population
\end{enumerate}
Step 2 and 4 are where negative selection and clonal selection is relevant in most forms of AIS algorithms.\\\\
At the time of writing 5 main concepts are used in an AIS. The aforementioned negative selection, clonal selection and, more recently, the immune network theory, the danger theory and the dendritic cells theory. 

\section{Negative Selection in AIS}

A typical AIS has a set of detectors which react to any non-self data in the system. The most common way to generate these detectors is to create them randomly and let them undergo a negative selection in which they are presented to self data sets. If one of the detectors recognizes a self data, the affinity is therefore high enough, it is destroyed. In this case the AIS follows the process that is found in the BIS.\\\\ 
It is important to decide in which way affinity is measured and which conditions trigger an immune reaction. If the used data consists of numerical values, or is easily converted into a vector thereof, the Euclidean distance \cite{howard} is commonly used as a mean to measure affinity [TAN16]:\\\\
\begin{math}
\sqrt{\sum_{i=1}^{n}(xi-yi)^2}
\end{math}\\\\
The Euclidean distance measures the straight-line distance between two points in Euclidean space. In the formula above xi and yi are values of two n-dimensional vectors x and y \cite{howard}.  

Another way of measuring the affinity is the use of different variants of the Hammington distance. The Hammington distance is the number of bits which must be changed in two bit strings of the same length to make both strings identical \cite{hammington}. In an binary string the distance can be measured by the number of ones after applying a XOR operation on both strings. A common variant of this is the use of the so called r-continuous bits. In this case a detector recognizes an element if r-continuous bits are identical with the element.\\
\begin{table*}[htbp]
	\begin{tabular}{ll}
Non-self element & 0010110\\
Detector & 0011101
	\end{tabular}
\end{table*}\\
In the example above the first 3 continuous bits match in both strings. If the threshold of the detector is r = 3, it would react to this bit string if the number of continues bits is 3 or higher.
In case of recommender systems another way to measure the affinity is to use the Pearson product-moment correlation \cite{pearson}. However this correlation is not suited for optimization tasks or, specifically, the use in the travelling salesman problem. 
\section{Clonal Selection in an AIS}
Negative Selection is useful for generating a population of detectors. To mimic the learning abilities of the biological immune system, the clonal selection principle can be used. The CLONALG algorithm was proposed by \cite{DEC02} in 2002 and is the foundation of many AIS algorithms using the clonal selection principle. This thesis focuses on the CLONALG algorithm and some of its variations, as these algorithms will be used to generate the data in Chapter \ref{chap:eva}.
\subsection{CLONALG}
The CLONALG algorithm mimics the clonal selection of the BIS on an abstract level. It will be applied mainly at step 4 in the basic AIS sequence shown in Chapter \ref{chap:ais}. The algorithm starts with generating an initial population C. It then calculates the affinity of the population to an antigen which is called the fitness. The n best antibodies of the population C are chosen, determined by a fixed fitness value and form the antibody set S. Every Ab in S is cloned and represents the clone set P. Now the clone set is mutated, every clone randomly changed relatively to its affinity value. After the mutation the n best clones out of P are chosen. Then a new population is generated and the process begins anew until a stopping condition is met.\\
An example of pseudocode based on \cite{RIFF09} can be illustrated as follows:
\begin{algorithm}
	Generate initial population C of A antibodies\\
	Calculate Fitness(C)\\
	\While{stopping condition not met}{
	S= Select the n best antibodies from C\\
	P= Generate clones of the antibodies in S\\
	Mutate(P)\\
	C= Select the n best antibodies out of P\\
	C= C + New population A-n}
	\caption{Simple CLONALG pseudo code}
\end{algorithm}\\
Usually the stopping condition is a given amount of evaluation where no increase in fitness is achieved or has fallen below a given threshold. The initial CLONALG algorithm as proposed by \cite{DEC02} operates with static parameters and does not adjust anything besides the mutation. Different parameters are needed for different applications fields as stated in \cite{DEC02}. These parameters must be changed beforehand and cannot adapt dynamically during the runtime of the algorithm.\\\\
The main parameters of the CLONALG are population size, selection size, clone factor and random replacements. Population size is the initial set of Ab the algorithm starts with. Selection size is the number of Ab chosen for cloning out of the population size. The clone factor determines how many clones of the selected Ab are generated and random replacements are new Ab added to the population at the end of every iteration to keep the population partly randomized. Additionally, the mutation factor governs to what degree a clone will mutate.\\\\
Although the algorithm is simple and efficient in solving different tasks like multimodal problems or pattern recognition, drawbacks do exist \cite{Garret04}. Choosing how many members should be cloned is difficult. The lack of adaptive parameters can lead to inefficiency caused by bad scalability and too many evaluations \cite{Garret04}.
\subsection{Adaptive CLONALG variants}
To make the algorithm more efficient and adaptive, some variants have been proposed. There are different parameter control strategies for the CLONALG algorithm. One of these variants is proposed by \cite{RIFF09} and is based on the concept of reinforcement learning. Ab sets are either rewarded for high affinity or penalized for a low one. This is achieved through population control. The reward consists of an increase in Ab population for a given set and the penalty is the decrease in population \cite{RIFF09}. The mutation factor is governed by population size, allowing the algorithm to adjust the core parameters during runtime and making it more efficient in problem solving and hardware usage \cite{RIFF09}.\\
Another method is proposed by \cite{Garret04} where some techniques of evolutionary algorithms are applied to the CLONALG. An algorithm based on this concept will be evaluated in chapter \ref{chap:eva}.
 




