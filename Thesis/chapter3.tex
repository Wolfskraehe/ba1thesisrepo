\chapter{Artificial Immune System}
\label{chap:ais}
\section{Basics of an AIS}
A definition of an AIS is given by [TAN16]:
"ArtiÔ¨Åcial Immune System (AIS) is a computational intelligence system inspired by the working mechanism and principles of the biological immune system"
An AIS can be used in machine learning and is comparable to an artificial neural net in terms of different application fields.
It shares some similarities with genetic algorithms due to the cloning and mutation process in clonal selection.\\\\
Generally speaking: a set of detectors (antibodies) react to a specific anomaly (antigen). This anomaly could be a malicious code, an IP address and port combination that is not allowed in the network or a pattern that has to be classified. What represents an antigen in the algorithm completely depends on the context and the use of the algorithm. An AIS can be used in an Intrusion Detection System [PAM17], learning and pattern recognition [DEC02], for recommender systems, data mining and clustering [BUR14] and optimization [NAN08].\\

The basic steps of an AIS can be summarized as [TAN16]:
\begin{enumerate}
	\item 	Initialize/present antigen
	\item 	Initialize antibody population
	\item 	Calculate affinity for each antibody to the antigen
	\item 	Check lifecycle of each antibody and update it
	\item 	If stopping condition met go to 6 else go to 3
	\item 	Output antibody population
\end{enumerate}\\\\Step 2 and Step 4 are the steps where negative selection and clonal selection will be relevant in most forms of AIS algorithms.\\\\
At the time of writing there are mainly 5 concepts that are used in an AIS. The aforementioned negative selection, clonal selection and more recently the immune network theory, the danger theory and the dendritic cells theory. 

\section{Negative Selection in AIS}

A typical AIS has a set of detectors which react to any non-self data of the system. The most common way to generate these detectors is to create them randomly and let them undergo a negative selection in which they are presented to self data sets. If one of the detectors recognizes a self data, therefore the affinity is high enough, it will be destroyed. In this case the AIS follows the process that is found in the BIS.\\\\ 
It is important to decide in which way affinity will be measured and which conditions will trigger an immune reaction. If the data that is used consists of numerical values, or is easily converted into a vector of those, the Euclidean distance [4] is commonly used as a mean to measure affinity [TAN16]: (Euclidean Distance Formula)\\\\
The Euclidean distance gives us the straight-line distance between two points in an Euclidean space. In the formula above xi and yi are values from two n-dimensional vector x and y.  

Another possibility is the use of different variants of the Hammington distance [3]. The Hammington distance is the number of bits that must be changed in two bit strings of the same length to make both strings identical. A common variant of this is the use of the so called r-continues bits. In this case a detector recognizes an element if r continues bit are identical with the element.\\
\begin{table*}[htbp]
	\begin{tabular}{ll}
Non-self element & 0010110\\
Detector & 0011101
	\end{tabular}
\end{table*}\\
In the example above the first 3 continues bit match in both strings. If the threshold of the detector is r = 3, it would react to this bit string if the number of continues bits is 3 or higher.
In case of recommender systems another way to measure the affinity is to use the Pearson correlation [5]. But the Pearson correlation is not suited for optimization tasks or specifically the use in the travelling salesman problem. 
\section{Clonal Selection in an AIS}
Negative Selection is good for generating a population of detectors. To mimic the learning abilites of the biological immune system, the clonal selection principle can be used. The CLONALG algorithm was proposed by [DEC02] in 2002 and is the foundation of many AIS algorithms that use the clonal selection principle. The CLONALG is also present in more recent variations of the AIS like in aiNet and in algorithms the utilize the immune network theory [CITACION NEEDED]. This thesis will focus on the CLONALG algorithm and some of its variations, as these algorithms will be used to generate the data in \ref{chap:eva}.
\subsection{CLONALG}
The CLONALG algorithm mimics the clonal selection of the BIS on an abstract level. It will be applied mainly at step 4 in the basic AIS sequence in \ref{chap:ais}. The algorithm starts with generating a initial population C. It then calculates the affinity of the population to an antigen which is called the fitness. The n best antibodies of the population C will be chosen, determined by a fixed fitness value, and form the antibody set S. Every antibody in S will be cloned and represents our clone set P. Now the clone set will be mutated, every clone get randomly changed relatively to its affinity value. After the mutation the n best clones out of P are chosen. Then a new population will be generated and the process begins annew till a stopping condition is met.\\
A simple pseudocode can look like this, based on [RIFF09]:
\begin{algorithm}
	Generate initial population C of A antibodies\\
	Calculate Fitness(C)\\
	\While{stopping condition not met}{
	S= Select the n best antibodies from C\\
	P= Generate clones of the antibodies in S\\
	Mutate(P)\\
	C= Select the n best antibodies out of P\\
	C= C + New population A-n}
	\caption{Simple CLONALG pseudocode}
\end{algorithm}\\
The initial CLONALg algorithm as proposed by [DEC02] operates with static paramters and don't adjust anything besides the mutation. Different parameters are needed for different applications fields as was also stated in [DEC02]. This paramters must be changed beforehand and can't adapt dynamically during the runtime of the algorithm.
\subsection{Adaptive CLONALG variants}
To make the algorithm more efficient and adaptive, some variants where proposed. There are different paramter control stragegies for the CLONALG algorithm. One of these variants is proposed by [RIFF09]. It is based on the idea of reinforcement learning. The antibody sets will be either rewarded for a high affinity or penalized for a low one. This will be achieved through population control. The reward is the increase in antibody population for a given set and the penalty is the decrease in population. 
 




